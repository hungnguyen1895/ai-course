{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI-Homework4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTOdXCb2vdue",
        "colab_type": "text"
      },
      "source": [
        "## Things I have learned in this class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjDUri8PlRM9",
        "colab_type": "text"
      },
      "source": [
        "### Artificial Intelligence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqD8JYILlUdt",
        "colab_type": "text"
      },
      "source": [
        "\"In computer science, artificial intelligence, sometimes called machine intelligence, is intelligence demonstrated by machines\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRGLpZlklc4U",
        "colab_type": "text"
      },
      "source": [
        "## Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0FUSxMdlVJW",
        "colab_type": "text"
      },
      "source": [
        "\"Machine learning is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vk_XaJsfllTC",
        "colab_type": "text"
      },
      "source": [
        "### Deep Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBd8gAzulfQM",
        "colab_type": "text"
      },
      "source": [
        "\"Deep learning is part of a broader family of machine learning methods based on artificial neural networks. Learning can be supervised, semi-supervised or unsupervised.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaJ8pgcJvjBe",
        "colab_type": "text"
      },
      "source": [
        "### Gradient Descent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mQVp1OMw48I",
        "colab_type": "text"
      },
      "source": [
        "\"Gradient descent is an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient. In machine learning, we use gradient descent to update the parameters of our model. Parameters refer to coefficients in Linear Regression and weights in neural networks.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wS5yWOLw_Vl",
        "colab_type": "text"
      },
      "source": [
        "### Learning Rate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KKD0YEFxPmW",
        "colab_type": "text"
      },
      "source": [
        "\"The size of these steps is called the learning rate. With a high learning rate we can cover more ground each step, but we risk overshooting the lowest point since the slope of the hill is constantly changing. With a very low learning rate, we can confidently move in the direction of the negative gradient since we are recalculating it so frequently. A low learning rate is more precise, but calculating the gradient is time-consuming, so it will take us a very long time to get to the bottom.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLhapPTZxoIx",
        "colab_type": "text"
      },
      "source": [
        "### Cost Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTYefRHBxsPA",
        "colab_type": "text"
      },
      "source": [
        "\"A Loss Functions tells us “how good” our model is at making predictions for a given set of parameters. The cost function has its own curve and its own gradients. The slope of this curve tells us how to update our parameters to make the model more accurate.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGejFDmfxuLt",
        "colab_type": "text"
      },
      "source": [
        "### Activation Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5UnZABwzBZY",
        "colab_type": "text"
      },
      "source": [
        "\"the activation function of a node defines the output of that node given an input or set of inputs. A standard computer chip circuit can be seen as a digital network of activation functions that can be \"ON\" (1) or \"OFF\" (0), depending on input. This is similar to the behavior of the linear perceptron in neural networks\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TFRKLUsRzCF9",
        "colab_type": "text"
      },
      "source": [
        "### Dense Layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUdl66m71tBx",
        "colab_type": "text"
      },
      "source": [
        "\"A dense layer is just a regular layer of neurons in a neural network. Each neuron recieves input from all the neurons in the previous layer, thus densely connected.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pj074EB51tfw",
        "colab_type": "text"
      },
      "source": [
        "### Overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS-dpCWk1_yS",
        "colab_type": "text"
      },
      "source": [
        "\"Overfitting is a modeling error which occurs when a function is too closely fit to a limited set of data points. Overfitting the model generally takes the form of making an overly complex model to explain idiosyncrasies in the data under study.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIRkwtOw2ALK",
        "colab_type": "text"
      },
      "source": [
        "### Underfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXBA611k2FEx",
        "colab_type": "text"
      },
      "source": [
        "\"Underfitting occurs when a model is too simple — informed by too few features or regularized too much — which makes it inflexible in learning from the dataset.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLH-WjB82FYp",
        "colab_type": "text"
      },
      "source": [
        "### Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdQa06w92KTg",
        "colab_type": "text"
      },
      "source": [
        "\"Dropout is a regularization technique patented by Google for reducing overfitting in neural networks by preventing complex co-adaptations on training data. It is a very efficient way of performing model averaging with neural networks.\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDb9gxK6JgBR",
        "colab_type": "text"
      },
      "source": [
        "### How to build model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdLAqwsHJiJp",
        "colab_type": "text"
      },
      "source": [
        "      # set up the layers\n",
        "\n",
        "      model = keras.Sequential([\n",
        "          keras.layers.Flatten(input_shape=(28, 28)),\n",
        "          keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "          keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "          keras.layers.Dense(32, activation=tf.nn.relu),\n",
        "          keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "\n",
        "      ])\n",
        "\n",
        "      # compile the model\n",
        "\n",
        "      model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "      model.summary()\n",
        "      # train the model\n",
        "      epochs = 5\n",
        "      history = model.fit(train_images, \n",
        "                            train_labels, \n",
        "                            epochs=epochs,  \n",
        "                            validation_data=(test_images, test_labels))"
      ]
    }
  ]
}